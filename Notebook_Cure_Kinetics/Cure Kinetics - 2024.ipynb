{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cure Kinetics (28 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As it was explained during the lectures, a significant part of research in composites manufacturing is involved in analyzing curing processes of thermoset polymers.Thermoset resins, such as epoxy, undergo a curing process driven by chemical reactions. These reactions result in the creation of covalent bonds among monomers, ultimately forming polymer chains. This curing process is quantified by the parameter known as the 'degree of cure,' denoted as $\\alpha$. Initially, in the absence of any covalent bonds, the material consists solely of individual monomers. In this scenario, it can be asserted that no bonding has occurred, resulting in $\\alpha = 0$. However, upon the addition of a hardener, the monomers initiate the formation of polymer chains through the establishment of covalent bonds. When all the monomers have become part of polymer chains through these covalent bonds, it is deemed that the degree of cure has reached its maximum, $\\alpha = 1$\n",
    "\n",
    "### Chemical reactions occur through contact of two active groups belonging to different molecules (for example of epoxy and of a hardener). Elevated cure temperatures are essential to trigger and maintain the chemical reactions responsible for converting the thermoset into a fully cured state. Whenever resin and hardener molecules (after mixing) are provided with more kinetic energy, they are more likely to shift and collide with neighbouring molecules, increasing the chances of curing reactions. Additionally, when more time is given to two reactants, the probability of a necessary collision for bonding increases. As a result, these phenomena are highly influenced by resin chemistry, catalyst reactivity, cure temperature, and the presence of inhibitors or accelerators.\n",
    "\n",
    "### Therefore, we can say that the degree of cure $\\alpha$ is a function of both temperature and time. $$\\alpha = f(T,t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cure kinetics is concerned with the rates of the chemical reactions in a curing process. This is relevant, since the cure kinetics can help predict the thermoset cure and therefore also determines the manufacturing process and (partially) the final material properties. When cure kinetics are understood, they can be used to predict the degree of cure $\\alpha$ of a certain process. To make this type of prediction, DSC measurement data can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before starting to work on the questions and to achieve a better understanding of the topic, it is highly recommended for you to read the paper provided with this notebook (Kailong Jin, William H. Heath, John M. Torkelson, Kinetics of multifunctional thiol-epoxy click reactions studied by differential scanning calorimetry: Effects of catalysis and functionality. Polymer. 2015; 81: 70-78)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differential Scanning Calorimetry (DSC) experiments are frequently used to evaluate the cure kinetics parameters involved in the curing of thermosets. To show this correlation, three tests were performed in isothermal conditions for the polymerization of a thermoset at three different temperatures. The .xlsx files which contain these raw isothermal DSC measurements were attached to this notebook.\n",
    "#### In the cell below, plot the relevant DSC measurement data for all of the three cases in a single figure. Don't forget to label the axis (ylabel = H[W/g], xlabel=t[min]).\n",
    "#### NOTE: \n",
    "#### 1. The unit used for heat flow data in the .xlsx files is [mW/s].\n",
    "#### 2. The weights for the specimens are mentioned in the respective .xlsx files.\n",
    "#### 3. Data analysis needs to be carried out in order to determine what is relevant and what is machine data/noise. Carry out cleaning of data if necessary. Mention the steps followed (if applicable) as part of your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------READING FILE-----------\n",
      "---------FILE READ---------\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge in Linear Least Squares",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 94\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# QUESTION 1\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m t_120, hfu_120, T_120\u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_120\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_name_120\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m101\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m t_150, hfu_150, T_150\u001b[38;5;241m=\u001b[39m read_file(file_150, s_name_150, \u001b[38;5;241m101\u001b[39m)\n\u001b[0;32m     96\u001b[0m t_180, hfu_180, T_180\u001b[38;5;241m=\u001b[39m read_file(file_180, s_name_180, \u001b[38;5;241m71\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 65\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(file_name, sheet_name, wl)\u001b[0m\n\u001b[0;32m     61\u001b[0m heat_flow_unsub_list \u001b[38;5;241m=\u001b[39m heat_flow_unsub_list\u001b[38;5;241m/\u001b[39mweight \u001b[38;5;66;03m# [W/g]\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Filtering of the data\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m filtered_tot_h_flow \u001b[38;5;241m=\u001b[39m \u001b[43msavgol_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheat_flow_unsub_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolyorder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m filtered_tot_h_flow \u001b[38;5;241m=\u001b[39m filtered_tot_h_flow \u001b[38;5;241m-\u001b[39m filtered_tot_h_flow[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(filtered_tot_h_flow)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.95\u001b[39m)]\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time_list, filtered_tot_h_flow, sample_t_list\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\signal\\_savitzky_golay.py:352\u001b[0m, in \u001b[0;36msavgol_filter\u001b[1;34m(x, window_length, polyorder, deriv, delta, axis, mode, cval)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;66;03m# Do not pad. Instead, for the elements within `window_length // 2`\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;66;03m# of the ends of the sequence, use the polynomial that is fitted to\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;66;03m# the last `window_length` elements.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m     y \u001b[38;5;241m=\u001b[39m convolve1d(x, coeffs, axis\u001b[38;5;241m=\u001b[39maxis, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 352\u001b[0m     \u001b[43m_fit_edges_polyfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolyorder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderiv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m# Any mode other than 'interp' is passed on to ndimage.convolve1d.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     y \u001b[38;5;241m=\u001b[39m convolve1d(x, coeffs, axis\u001b[38;5;241m=\u001b[39maxis, mode\u001b[38;5;241m=\u001b[39mmode, cval\u001b[38;5;241m=\u001b[39mcval)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\signal\\_savitzky_golay.py:223\u001b[0m, in \u001b[0;36m_fit_edges_polyfit\u001b[1;34m(x, window_length, polyorder, deriv, delta, axis, y)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03mUse polynomial interpolation of x at the low and high ends of the axis\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03mto fill in the halflen values in y.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03mThis function just calls _fit_edge twice, once for each end of the axis.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m halflen \u001b[38;5;241m=\u001b[39m window_length \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 223\u001b[0m \u001b[43m_fit_edge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalflen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m          \u001b[49m\u001b[43mpolyorder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderiv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m    226\u001b[0m _fit_edge(x, n \u001b[38;5;241m-\u001b[39m window_length, n, n \u001b[38;5;241m-\u001b[39m halflen, n, axis,\n\u001b[0;32m    227\u001b[0m           polyorder, deriv, delta, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\signal\\_savitzky_golay.py:193\u001b[0m, in \u001b[0;36m_fit_edge\u001b[1;34m(x, window_start, window_stop, interp_start, interp_stop, axis, polyorder, deriv, delta, y)\u001b[0m\n\u001b[0;32m    189\u001b[0m xx_edge \u001b[38;5;241m=\u001b[39m xx_edge\u001b[38;5;241m.\u001b[39mreshape(xx_edge\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Fit the edges.  poly_coeffs has shape (polyorder + 1, -1),\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# where '-1' is the same as in xx_edge.\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m poly_coeffs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolyfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_stop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwindow_start\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mxx_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolyorder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deriv \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    197\u001b[0m     poly_coeffs \u001b[38;5;241m=\u001b[39m _polyder(poly_coeffs, deriv)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpolyfit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\polynomial.py:668\u001b[0m, in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    666\u001b[0m scale \u001b[38;5;241m=\u001b[39m NX\u001b[38;5;241m.\u001b[39msqrt((lhs\u001b[38;5;241m*\u001b[39mlhs)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    667\u001b[0m lhs \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m scale\n\u001b[1;32m--> 668\u001b[0m c, resids, rank, s \u001b[38;5;241m=\u001b[39m \u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    669\u001b[0m c \u001b[38;5;241m=\u001b[39m (c\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m/\u001b[39mscale)\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# broadcast scale coefficients\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;66;03m# warn on rank reduction, which indicates an ill conditioned matrix\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mlstsq\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py:2300\u001b[0m, in \u001b[0;36mlstsq\u001b[1;34m(a, b, rcond)\u001b[0m\n\u001b[0;32m   2297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_rhs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2298\u001b[0m     \u001b[38;5;66;03m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[39;00m\n\u001b[0;32m   2299\u001b[0m     b \u001b[38;5;241m=\u001b[39m zeros(b\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (m, n_rhs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mb\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m-> 2300\u001b[0m x, resids, rank, s \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2302\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py:101\u001b[0m, in \u001b[0;36m_raise_linalgerror_lstsq\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_lstsq\u001b[39m(err, flag):\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge in Linear Least Squares\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge in Linear Least Squares"
     ]
    }
   ],
   "source": [
    "# File names\n",
    "file_120 = \"LME_0_13_120.xlsx\"\n",
    "s_name_120 = \"Sheet1\"\n",
    "file_150 = \"LME_0_12b_150.xlsx\"\n",
    "s_name_150 = \"Sheet1\"\n",
    "file_180 = \"LME_0_11_180.xlsx\"\n",
    "s_name_180 = \"Sheet1\"\n",
    "\n",
    "\n",
    "## to DO FILTER DATA\n",
    "def read_file(file_name, sheet_name, wl):\n",
    "    # Function that reads the correct file and gives the required data\n",
    "    # ATTENTION: the file need sto be in the same folder as the code\n",
    "    # Input: File name, sheet name, final value to read from the rows in the excel +1 (final row+ 1)\n",
    "    # Outputs : time list, filtered heat flow, temperature iof the sample\n",
    "    print(\"---------READING FILE-----------\")\n",
    "    dfv = pd.read_excel(file_name,sheet_name=sheet_name, usecols=\"B\",header=None, skiprows=0, nrows=25)\n",
    "    # Reading of the specific points\n",
    "    weight = float(dfv.iloc[7, 0])             # [mg]\n",
    "    weight = weight/1000\n",
    "\n",
    "    n_point= int(dfv.iloc[21, 0])+37           # Number of rows to read\n",
    "\n",
    "    # Caluclation of all the reange that need sto be read\n",
    "    l_num = n_point-35\n",
    "   \n",
    "    \n",
    "    # reading of the file for \n",
    "    df = pd.read_excel(file_name,sheet_name=sheet_name, usecols=\"B, C, F\",header=None, skiprows=0, nrows=l_num)\n",
    "    print(\"---------FILE READ---------\")\n",
    "    # Creation of the lists\n",
    "    time = df.iloc[35:-1, 0].tolist()            # [min]\n",
    "    heat_flow_unsub = df.iloc[35:-1, 1].tolist() # [mW]\n",
    "    #program_t = df.iloc[0:-1, 2].tolist()       # [C]\n",
    "    sample_t = df.iloc[35:-1, 2].tolist()        # [C]\n",
    "    #approx_gas_flow = df.iloc[0:-1, 4].tolist() # [-]\n",
    "    #heat_flow_cali = df.iloc[0:-1, 5].tolist()  # [-]\n",
    "\n",
    "\n",
    "    # Conversion into np arrays and into the correct units\n",
    "    time_list= np.array(time, dtype=float)              # [min]\n",
    "    sample_t_list = np.array(sample_t, dtype = float)\n",
    "    sample_t_list = np.array(sample_t, dtype=float)\n",
    "    heat_flow_unsub_list = np.array(heat_flow_unsub, dtype=float)\n",
    "    heat_flow_unsub_list = heat_flow_unsub_list/1000    # [W]\n",
    "\n",
    "    # Conversion from W/s to W/g as an accumulation of heat\n",
    "    time_list = time_list*60\n",
    "    sample_t_list = sample_t_list+273.15\n",
    "    \"\"\" tot_h = np.zeros(len(time_list))\n",
    "    for i in range(len(heat_flow_unsub_list)):\n",
    "        if i == 0: \n",
    "            dt = time_list[i] * 60\n",
    "            tot_h[i] = heat_flow_unsub_list[i] * dt     # [W]\n",
    "            \n",
    "        else:\n",
    "            dt = (time_list[i]-time_list[i-1]) * 60\n",
    "            tot_h[i] = heat_flow_unsub_list[i] * dt     # [W]\n",
    "            \"\"\"\n",
    "    # devide by weight\n",
    "    heat_flow_unsub_list = heat_flow_unsub_list/weight # [W/g]\n",
    "\n",
    "\n",
    "    # Filtering of the data\n",
    "    filtered_tot_h_flow = savgol_filter(heat_flow_unsub_list, window_length=wl, polyorder=3)\n",
    "    filtered_tot_h_flow = filtered_tot_h_flow - filtered_tot_h_flow[int(len(filtered_tot_h_flow)*0.95)]\n",
    "    return time_list, filtered_tot_h_flow, sample_t_list#, program_t, sample_t, approx_gas_flow, heat_flow_cali\n",
    "\n",
    "def plot_DSC (t_120, hf_120, t_150, hf_150, t_180, hf_180):\n",
    "    # Fuunction in order to plot the DSC graphs\n",
    "    # Inputs: time array 120, heat flow array 120, time arrray 150, heat flow array 150m, time array 180, heat flow array 180\n",
    "    # Output: plot\n",
    "\n",
    "    \n",
    "    t_120 = t_120/60\n",
    "    t_150 = t_150/60\n",
    "    t_180 = t_180/60\n",
    "    plt.plot(t_120, hf_120, label = \"T = 120 º\")\n",
    "    plt.plot(t_150, hf_150, label = \"T = 150 º\")\n",
    "    plt.plot(t_180, hf_180, label = \"T = 180 º\")\n",
    "    plt.xlim(0, 350)\n",
    "    plt.ylim(bottom = 0)\n",
    "    plt.ylabel(\"Heat flow [W/g]\")\n",
    "    plt.xlabel(\"Time [min]\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(\"DSC.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "# QUESTION 1\n",
    "t_120, hfu_120, T_120= read_file(file_120, s_name_120, 101)\n",
    "t_150, hfu_150, T_150= read_file(file_150, s_name_150, 101)\n",
    "t_180, hfu_180, T_180= read_file(file_180, s_name_180, 71)\n",
    "plot_DSC(t_120, hfu_120, t_150, hfu_150, t_180, hfu_180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After visualizing the heat generation curves, explain why and how isothermal DSC measurement data can be related to the curing rate of a thermoset resin. Why is there a peak and what can it be related to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "Why: Curing of a thermoset resin is an exothermic process due to forming of crosslinks. The energy released by the forming of these crosslinks is emitted as reaction heat which in turn can be measured by the DSC (heat flow). \n",
    "How: The relation can be described as Measured heat flow ∝ Reaction rate or better with (dQ)\\(dt) = ΔH_{total} * (dα)/(dt) Where dα = curing rate, because α = degree of cure (fraction cured (ranging from 0-1)).\n",
    "\n",
    "Why is there a peak: The curing process is not constant and can be devided into 4 phases \n",
    "1) Start (low heat flow): Before initiation some crosslinks are formed over time but neglegable\n",
    "2) Increase (increasing heat flow): After initiation more crosslinks are formed creating more heat/energy which is helps with forming other crosslinks. dα/dt keeps increasing.\n",
    "3) Peak (max heat flow): dα/dt reaches its peak, highest amount of reactions taking place.\n",
    "4) Decrease (reducing heat flow): Due to restriction in mobility due to the crosslinks. A network is formed by the crosslinks, making it harder for the remaining crosslinks to find a 'space' to link onto another polymer.\n",
    "\n",
    "What can it be related to: Chemically it can best be described by the autocatalytic behaviour, which keeps increasing dα/dt until the negative effect of the diffusion limitations matches the positives of the autocatalic behaviour. From that point onwards the diffusion will keep increasing, decreasing the number of reactions and decreasing dα/dt. Therefore going over the peak that is shown in the DSC measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As mentioned, the just plotted isothermal DSC data  can be used to obtain an estimation of degree of cure $\\alpha$ vs. time $t$. To do so, it first has to be assumed that the heat flow is proportional to the degree of cure.  $$\\Delta H_{max} \\equiv \\alpha = 1$$\n",
    "#### Where  $\\Delta H_{max} $ identifies the maximum total heat of reaction found for the three DSC measurements.\n",
    "#### $\\Delta H_{max} = max(\\Delta H_{max_{120}}, \\Delta H_{max_{150}}, \\Delta H_{max_{180}})$\n",
    "#### Overall, the formula above expresses how the total generated heat flow while curing corresponds to a complete degree of cure for the reaction (100%).\n",
    "#### Then, this assumption is used to normalize the heat flow measurement. This normalized heat flow can now be related to the curing rate. $$\\frac{d\\alpha}{dt} = \\frac{1}{\\Delta H_{max}} \\frac{dH(t)}{dt}$$\n",
    "#### Finally, integrating this result leads to the relationship of the degree of cure $\\alpha$ vs. time $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the assumptions and information provided above to plot the degree of cure $\\alpha$ vs. time $t$, using the provided data. Plot all cases in a single figure. Make sure to plot over a time interval which suits the results, include a legend and axes labels with units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add the max heat\n",
    "def heat_add(h_flow, time, T, T_req):\n",
    "    # Function that integrates the heat flow over time in order to the total amount of heat from the exothermal reaction, and stores teh temperatures for future processing\n",
    "    # Inputs: Heat flow array in W, tiem array in second, temperature\n",
    "    # Outputs: degree of cure array\n",
    "\n",
    "    len_arr = np.count_nonzero(h_flow>0.0000000)          # Lenght of the array positive  [int] filtering the very small initial value\n",
    "    #tot_h = np.zeros(len_arr)   # List of the heat flow\n",
    "    #positive_time = np.zeros(len_arr)\n",
    "    tot_h = []\n",
    "    positive_time = []\n",
    "    T_list = []\n",
    "    tp = 0                      # Time varaible for calculation\n",
    "    hp = 0                      # Heat variable for calculation\n",
    "    q = True                       # variable for shifting time\n",
    "    # Make sure that it has achived the temperature of the isothermal\n",
    "    for i in range(len_arr):\n",
    "        if (h_flow[i]>0.0000000 and T[i]>T_req):                      # We asume that if the heat is negative that means that there is no reactions happening and that the that shouldnt be taken into account for the curing\n",
    "            if q==True:\n",
    "                ft=time[i]\n",
    "                q=False\n",
    "            h_t = h_flow[i]*(time[i] - tp)\n",
    "            \n",
    "            tp = time[i]\n",
    "            tot_h.append( h_t + hp)\n",
    "            positive_time.append( time[i]-ft)   # Normalize the time so that it starts at the first curing time\n",
    "            T_list.append(T[i])\n",
    "            hp = h_t + hp \n",
    "\n",
    "    # If we look in detail at the line for 180 deg we see that it is not filtereed perfectly. This actually okay, If we look at the amount of cure after it crosses 0 for the first time the degree of cure does not change that much\n",
    "    # CURE KINETICS MODELS ARE LEATIVE\n",
    "    return tot_h , positive_time, T_list\n",
    "\n",
    "def plot_cure(t120, a_t_120, t150, a_t_150, t180, a_t_180):\n",
    "    # Fuunction in order to plot the DSC graphs\n",
    "    # Inputs: time array 120, heat flow array 120, time arrray 150, heat flow array 150m, time array 180, heat flow array 180\n",
    "    # Output: plot\n",
    "    t120 = np.array(t120)/60\n",
    "    t150 = np.array(t150)/60\n",
    "    t180 = np.array(t180)/60\n",
    "    plt.plot(t120, a_t_120, label = \"T= 120º\")\n",
    "    plt.plot(t150, a_t_150, label = \"T= 150º\")\n",
    "    plt.plot(t180, a_t_180, label = \"T= 180º\")\n",
    "    plt.grid()\n",
    "    plt.title(\"cure over time in log scale\")\n",
    "    plt.xlabel(\"Time [min]\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylabel(\"Degree of cure [%]\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"Cure.jpg\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(t120, a_t_120, label = \"T= 120º\")\n",
    "    plt.plot(t150, a_t_150, label = \"T= 150º\")\n",
    "    plt.plot(t180, a_t_180, label = \"T= 180º\")\n",
    "    plt.grid()\n",
    "    plt.title(\"Cure over time\")\n",
    "    plt.xlabel(\"Time [min]\")\n",
    "    plt.ylabel(\"Degree of cure [%]\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"Cure.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "# QUESTION 3\n",
    "heat_120 , pos_t_120, rT120= heat_add(hfu_120, t_120, T_120, 120+273.15)\n",
    "heat_150 , pos_t_150, rT150= heat_add(hfu_150, t_150, T_150, 150+273.15)\n",
    "heat_180 , pos_t_180, rT180= heat_add(hfu_180, t_180, T_180, 150+273.15)\n",
    "\n",
    "# fin the maximum heat\n",
    "max_heat = max(heat_120[-1], heat_150[-1], heat_180[-1])\n",
    "alpha_t_120 = heat_120/max_heat\n",
    "alpha_t_150 = heat_150/max_heat\n",
    "alpha_t_180 = heat_180/max_heat\n",
    "print\n",
    "plot_cure(pos_t_120, alpha_t_120, pos_t_150, alpha_t_150, pos_t_180, alpha_t_180)\n",
    "print(\"Enthalpy relase for 120º=\", heat_120[-1],\", For 150º= \", heat_150[-1],\"For 180º= \", heat_180[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.1: In the previous question you have generated graphs illustrating the relationship between the degree of cure $\\alpha$ and time t for three isothermal DSC measurements carried out at different temperatures. Provide your analysis regarding the maximum degree of cure visible in the generated graphs. Can you explain the correlation between the final degree of cure and cure temperature? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.2 : A graph correlating the degree of cure $\\alpha$ with cure time for isothermal cure cycles at six different cure temperatures is shown in the figure below. Compare your graph made in Question 3 with the given figure. Describe two similarities and at least one difference. Provide a potential reason for the difference(s) you observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion vs. ln(time) curves for an epoxy-amine system. From Wisanrakkit and Gillham, J. Appl. Poly. Sci. 42, 2453 (1991)\n",
    "<img src=\"Conversion-time-plot.jpg\" width=\"700\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Several cure kinetics models were formulated to predict and simulate experimental cure profiles of thermosetting resins in terms of curing rate. You will be putting to test one of the most widely used ones: the Kamal-Sourour model (shown below) $$\\frac{d\\alpha}{dt} = (k_1 + k_2 \\cdot \\alpha^m)(1 - \\alpha)^n$$\n",
    "#### Where $k_1$ and $k_2$ are rate constants, and  $m$ and $n$ are reaction orders.\n",
    "#### The reaction rate constants $k_1$ and $k_2$ strongly depend on cure temperature and follow an Arrhenius type relation, as shown by the equation:\n",
    "$$k_i = A_i \\cdot exp(-\\frac{E_i}{RT})$$\n",
    "$$i=1,2$$\n",
    "#### Where the pre-exponential factor $A_i$ represents a constant, $E_i$ is the activation energy (mol/J), R is the molar gas constant and T is the cure temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5.1: Using the experimental isothermal DSC data used in Question 1, you will set up the cure kinetics of the resin based on the Kamal Sourour model. To estimate the intial activation energy $E_1$ and $A_1$, plot $ln\\left(\\frac{d\\alpha}{dt}\\right)$ vs $\\frac{1}{T}$ for a low degree of cure based on the three DSC measurements given. Calculate $E_1$ and $A_1$ based on the graph.\n",
    "\n",
    "#### Hint: $\\alpha \\approx 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kamal_Sourour (cure1, t1, T1, cure2, t2, T2, cure3, t3, T3):\n",
    "    # Function to calulate E1 A1  using the kamal sourour model\n",
    "    # Inputs = cure over time array, time array corresponding to cure, Temparature of sample over time Gas constant\n",
    "    # Output = plot the linear regression, coefficent A coefficent E, da/dt120 array, da/dt150 array,da/dt180 array\n",
    "\n",
    "    # In order to get the coeffinect A1 and E1 we can solve the system of equations for aplpha alspmost 0:\n",
    "    # da/dt_1 = A_1 e( E_1/RT)\n",
    "\n",
    "    R = 8.31446261815324 # [J⋅K−1⋅mol−1]\n",
    "\n",
    "    # Find spline interpolation for later derivation at alpha = 0\n",
    "    c1 = InterpolatedUnivariateSpline(t1, cure1)\n",
    "    c1int= c1(t1)\n",
    "    c2 = InterpolatedUnivariateSpline(t2, cure2)\n",
    "    c2int= c2(t2)\n",
    "    c3 = InterpolatedUnivariateSpline(t3, cure3)\n",
    "    c3int= c3(t3)\n",
    "    # Check for mean square error of the interpolation\n",
    "    error1 = cure1 - c1int\n",
    "    rmse1 = np.sqrt(np.mean(error1**2))\n",
    "    error2 = cure2 - c2int\n",
    "    rmse2 = np.sqrt(np.mean(error2**2))\n",
    "    error3 = cure3 - c3int\n",
    "    rmse3 = np.sqrt(np.mean(error3**2))\n",
    "    print(\" Mean square root error of first interpolation = \", rmse1)\n",
    "    print(\" Mean square root error of second interpolation = \", rmse2)\n",
    "    print(\" Mean square root error of third interpolation = \", rmse3)\n",
    "    \n",
    "\n",
    "\n",
    "    dc1_dt1 = c1.derivative()(t1)\n",
    "    dc2_dt2 = c2.derivative()(t2)\n",
    "    dc3_dt3 = c3.derivative()(t3)\n",
    "    # Derivative when cure is 0\n",
    "\n",
    "    # Malke a loop untill the rms reduces by\n",
    "    a_max=0.01# Max alpha to asume that curing is still 0\n",
    "    r_l = [] # List of the mean square error\n",
    "    a_l = []   # List for the curing taken\n",
    "    run = True\n",
    "    while a_max<=0.1 and run==True:\n",
    "        # take the avearge ofer the Check \n",
    "        # lenght of averaged da/dt and T\n",
    "        l_avg1 = calc_t_a (cure1, a_max)\n",
    "        l_avg2 = calc_t_a (cure2, a_max)\n",
    "        l_avg3 = calc_t_a (cure3, a_max)\n",
    "        dc1_dt1_0 = np.mean(dc1_dt1[0:l_avg1])\n",
    "        dc2_dt2_0 = np.mean(dc2_dt2[0:l_avg2])\n",
    "        dc3_dt3_0 = np.mean(dc3_dt3[0:l_avg3])\n",
    "        \n",
    "        T_1_0 = np.mean(T1[0:l_avg1])\n",
    "        T_2_0 = np.mean(T2[0:l_avg2])\n",
    "        T_3_0 = np.mean(T3[0:l_avg3])\n",
    "    \n",
    "        # Make a linear fit of the  ln(da/dt) over 1/T\n",
    "        l_dc_dt = np.array([np.log(dc1_dt1_0), np.log(dc2_dt2_0), np.log(dc3_dt3_0)])\n",
    "        l_t =np.array([1/T_1_0, 1/T_2_0, 1/T_3_0])\n",
    "        coef = np.polyfit(l_t, l_dc_dt, 1)\n",
    "        poly1d_fn = np.poly1d(coef)\n",
    "\n",
    "        # calculate prediction of the line\n",
    "        y = l_dc_dt\n",
    "        y_pred = coef[0]*l_t+ coef[1]\n",
    "        SS_res = np.sum((y - y_pred)**2)\n",
    "        SS_tot = np.sum((y - np.mean(y))**2)\n",
    "        R2 = 1 - SS_res / SS_tot\n",
    "\n",
    "        #Calculate  normalized means square root error\n",
    "        \n",
    "        r_l.append(R2)\n",
    "        a_l.append(a_max)\n",
    "        \n",
    "        if R2 >0.99999 and a_max>0.001: # Stop when the relation between the new rms and the previous is of les than 2 %\n",
    "            print(\"Curing range used= [0,\",a_max,\"], R^2= \", R2 )\n",
    "            run= False\n",
    "            \n",
    "        a_max = a_max + 0.001\n",
    "    \"\"\"    plt.plot(a_l, r_l)\n",
    "    plt.ylabel(\"R^2\")\n",
    "    plt.xlabel(\"Cure range taken\")\n",
    "    plt.grid()\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "    # plot \n",
    "    plt.plot(l_t, l_dc_dt, \"o\", label = \"datapoints\")\n",
    "    plt.plot(l_t, poly1d_fn(l_t), '--k', label=f'$y = {coef[0]:f}x + {coef[1]:f}$')\n",
    "    plt.ylabel(\"ln(da/dt)\")\n",
    "    plt.xlabel(\"1/T [1/K]\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Calculate coefficnets\n",
    "    A = np.exp(coef[1])     # b = ln(A)\n",
    "    E = - R * coef[0]       # a = -E/R\n",
    "    print(\"A1 =\", A)\n",
    "    print(\"E1 =\", E)\n",
    "\n",
    "    return dc1_dt1, dc2_dt2, dc3_dt3, A, E\n",
    "\n",
    "def calc_t_a(cure, a):\n",
    "    # Function that calculate sthe amount of time untill a certain value of cure is achived\n",
    "    # Input = cure array, time array, cure top limit\n",
    "    # Output = integer the amount values to take into account for averaging\n",
    "    for i in range (len(cure)): \n",
    "        \n",
    "        if cure[i]>= a:\n",
    "            m= int(i-1)\n",
    "            break\n",
    "    return m\n",
    "\n",
    "\n",
    "def find_kamal_sour(da_dt120, T_120, c_120, da_dt180, T_180, c_180, A1, E1):\n",
    "    # Function to find the arhenious terms A2, E2, m and n through minimization of the sum of squares of residuals of the two functions\n",
    "    # Inputs = da/dt(120) array, temperature for 120 array, cure 120 array, da/dt(180) array, temperature for 180 array, cure 180 array, A1 and E1\n",
    "    # Outputs = A2, E2, m, n all floats\n",
    "\n",
    "    R = 8.31446261815324 # [J⋅K−1⋅mol−1]\n",
    "\n",
    "    # Combine the sets of curing, temperature and d alpha dt\n",
    "    a_all = np.concatenate([c_120, c_180])\n",
    "    T_all = np.concatenate([T_120, T_180])\n",
    "    da_dt_all = np.concatenate([da_dt120, da_dt180])\n",
    "\n",
    "    # Choose intital parameters: They have to be resonable (in this casew the initial guesses are from from the article)\n",
    "    p0 = [      7,     # A2\n",
    "      50000,   # E2 (J/mol)\n",
    "      2.0,     # m\n",
    "      1.0]     # n\n",
    "    \n",
    "    # Add bounds:\n",
    "    bounds = ( [0,   1e4, 0.1, 0.1], [1e8, 2e5, 5.0, 5.0] )\n",
    "    # run the fitting\n",
    "    print(\"---------------Fitting started---------------\")\n",
    "    popt, pcov = curve_fit(\n",
    "    wrapper,\n",
    "    (a_all, T_all),  # independent variables\n",
    "    da_dt_all,       # dependent variable\n",
    "    p0=p0,\n",
    "    bounds=bounds,\n",
    "    maxfev=50000)\n",
    "    print(\"---------------Fitting eneded---------------\")\n",
    "\n",
    "    # extract parameters\n",
    "    A2_fit, E2_fit, m_fit, n_fit = popt\n",
    "    print(\"Fitted parameters:\")\n",
    "    print(\"A2 =\", A2_fit)\n",
    "    print(\"E2 =\", E2_fit)\n",
    "    print(\"m  =\", m_fit)\n",
    "    print(\"n  =\", n_fit)\n",
    "\n",
    "\n",
    "    # Compariuosn with experimental results\n",
    "    da_dt120_fit = calc_da_dt(T_120, c_120, A1, E1, A2_fit, E2_fit, m_fit, n_fit)\n",
    "    da_dt180_fit = calc_da_dt(T_180, c_180, A1, E1, A2_fit, E2_fit, m_fit, n_fit)\n",
    "    a120r = calc_area(c_120, da_dt120)\n",
    "    a180r = calc_area(c_180, da_dt180)\n",
    "    a120f = calc_area(c_120, da_dt120_fit)\n",
    "    a180f = calc_area(c_180, da_dt180_fit)\n",
    "\n",
    "    plt.plot(c_120, da_dt120, label = \"Data of 120º\")\n",
    "    plt.plot(c_180, da_dt180, label = \"Data of 180º\")\n",
    "    plt.plot(c_120, da_dt120_fit, label =\"Curve fit 120º\")\n",
    "    plt.plot(c_180, da_dt180_fit, label =\"Curve fit 180º\")\n",
    "    plt.ylabel(\"da/dt\")\n",
    "    plt.xlabel(\"Cure\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # relative difference between real data and fitted data\n",
    "    r120 = abs(a120f-a120r)/a120r*100\n",
    "    r180 = abs(a180f-a180r)/a180r*100\n",
    "    print(\"Relative difference between fitted curve and real curve for 120º= \", r120, \"%\")\n",
    "    print(\"Relative difference between fitted curve and real curve for 180º= \", r180, \"%\")\n",
    "    return A2_fit, E2_fit, m_fit, n_fit\n",
    "\n",
    "def rate_model(a, T, A1, E1, A2, E2, m, n):\n",
    "    # Function of the Kamal Sourour\n",
    "    R = 8.31446261815324 # [J⋅K−1⋅mol−1]\n",
    "\n",
    "    # Keep a in numerical range\n",
    "    a = np.clip(a, 1e-12, 1 - 1e-12)\n",
    "    # Safe exponential\n",
    "    def safe_exp(x):\n",
    "        return np.exp(np.clip(x, -700, 700))\n",
    "    term1 = A1 * safe_exp(-E1 / (R * T))\n",
    "    term2 = A2 * safe_exp(-E2 / (R * T)) * a**m\n",
    "\n",
    "    return (term1 + term2) * (1 - a)**n\n",
    "    \n",
    "    \"\"\"return (A1*np.exp(-E1/(R*T)) + A2*np.exp(-E2/(R*T)) * a**m) * (1 - a)**n\"\"\"\n",
    "\n",
    "def wrapper(x, A2, E2, m, n):\n",
    "    # Function to be able to pass more variables than one in curve_fit\n",
    "    a, T = x\n",
    "    return rate_model(a, T, A1, E1, A2, E2, m, n)\n",
    "\n",
    "def calc_da_dt(T, C, A1, E1, A2, E2, m, n):\n",
    "    # Function to calculate the da/dt with the previously calculated paramters\n",
    "    # Input = Temperature array, Curing array, A1, E1, A2, E2, m, n\n",
    "    # Output = array with the da/dt\n",
    "\n",
    "    R = 8.31446261815324 # [J⋅K−1⋅mol−1]\n",
    "    da_dt_fit = np.zeros(len(C))\n",
    "    for i in range (len(C)):\n",
    "        k1 = A1 * np.exp(-E1/(R*T[i]))\n",
    "        k2 = A2 * np.exp(-E2/(R*T[i]))\n",
    "        tot = (k1 + k2*(C[i]**m))*(1-C[i])**n\n",
    "        \n",
    "        da_dt_fit[i] = tot\n",
    "    \n",
    "    return da_dt_fit\n",
    "\n",
    "def calc_area(cu, dadt):\n",
    "    # Function to calculate a rough estimate of the area under a curve\n",
    "    # Inputs = Cure array, da/dt array\n",
    "    # Outputs are aunder the curve\n",
    "    a = 0 # Area\n",
    "    for i in range (len (cu)-1):\n",
    "        c= cu[i+1]-cu[i]                # Width of the trapezoid area\n",
    "        at = (dadt[i+1]+dadt[i])/2      # Avearege degree of cure\n",
    "\n",
    "        a= a+c*at\n",
    "\n",
    "    return a\n",
    "\n",
    "# Find the kamal_sourour model parameters A1 and E1\n",
    "dc_dt120, dc_dt150, dc_dt180, A1, E1 = Kamal_Sourour(alpha_t_120, pos_t_120, rT120, alpha_t_150, pos_t_150, rT150, alpha_t_180, pos_t_180, rT180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5.2: Estimate the other four parameters of the Kamal Sourour model ($A_2$, $E_2$, m, n) so that they fit the data of the $120^\\circ$ C and $180^\\circ$ C cure given. Note that the Kamal model should be valid for the resin system with one set of variables, i.e. $A_1$, $A_2$, $E_1$, $E_2$, m and n, that should describe the resin behaviour at different cure cycles/temperatures. Report the values obtained. After obtaining the parameters, use them to create figures of conversion rate $\\frac{d\\alpha}{dt}$ vs degree of cure $\\alpha$ for these two cure temperatures. Compare these curves with the experimental results and comment on the fit you made with your model.\n",
    "\t\n",
    "\n",
    "#### Tip: parameters can be estimated by-\n",
    "#### 1. Making an initial guess of the parameters, \n",
    "#### 2. Minimising the sum of squared errors between the initial value and the data (fit to data), where m, n, $A_1$, $A_2$, $E_1$ and $E_2$ should be the same for the two datasets. Note that $E_1$ and $A_1$ can be taken from Question 5.1 and are not needed in the optimisation any more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find other kaml_sourour parameters A2, E2, m and n\n",
    "A2, E2, m, n = find_kamal_sour(dc_dt120, rT120, alpha_t_120, dc_dt180, rT180, alpha_t_180, A1, E1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5.3: The model you just made should be able to describe the behaviour of the resin at a cure temperature of $150^\\circ$ C. Verify whether your model is able to estimate the behaviour of the resin at this cure temperature by generating a graph $\\frac{d\\alpha}{dt}$ vs degree of cure $\\alpha$ for both the experimental data from Question 1 and your model. Finally, comment on the plot you obtained and on the accuracy of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify with the 150 curve\n",
    "dc_dt150_fit = calc_da_dt(rT150, alpha_t_150, A1, E1, A2, E2, m, n)\n",
    "\n",
    "plt.plot(alpha_t_150, dc_dt150, label =\"Data 150º\")\n",
    "plt.plot(alpha_t_150, dc_dt150_fit, label = \"Curve fit 150º\")\n",
    "plt.ylabel(\"da/dt\")\n",
    "plt.xlabel(\"Cure\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As mentioned at the beginning of this Notebook, thermoset polymers undergo a curing cycle to achieve hardening. This process involves the formation of covalent bonds between monomers, ultimately resulting in the creation of the polymer network. The amount of formed bonds, therefore the degree of cross-linking, directly impacts the glass transition temperature ($T_g$) of the material. In the initial stages of the curing cycle, when relatively few bonds or crosslinks have formed, the material exhibits a relatively low $T_g$. However, as the degree of cure increases, the $T_g$ of the material increases. \n",
    "\n",
    "#### The correlation between $T_g$ and the degree of cure is particularly crucial in the design and engineering of polymer-based products, as it allows for the precise tuning of material properties by controlling the curing parameters. By adjusting the degree of cross-linking through cure temperature and time, engineers can achieve specific material characteristics, such as stiffness, strength, resistance to heat, and dimensional stability, tailored to the requirements of a particular application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the glass transition temperature and explain what happens (on a microscale and chemical level) when a material transitions through this value. Please include an explanation on how this value depends on  the degree of cure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a thermosetting polymer, it is particularly relevant to have a model able to describe the physical changes encountered during the cure cycle.\n",
    "#### The following empirical relation (Di Benedetto equation) between glass transition temperature $T_g$ and conversion $\\alpha$ has this goal and identifies the vitrification limit of a polymer:\n",
    "####  $$ \\frac{T_g - T_{g0}}{T_{g\\infty} - T_{g0}} =  \\frac{\\lambda \\alpha}{1 - (1 - \\lambda)\\alpha}  $$\n",
    "\n",
    "#### In which $\\lambda = \\frac{\\Delta C_p}{\\Delta C_{p0}}$ is the ratio of the heat capacities of the fully reacted system and the initial system (therefore $\\lambda < 1$), $T_{g\\infty}$ is the $T_g$ of the fully reacted system, and $T_{g0}$ is the $T_g$ of the initial system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A dataset containing glass transition temperature $T_g$ and degree of cure $\\alpha$ values for Airstone 780E was provided with this notebook.\n",
    "#### Use the $T_{g}$ values to fit the model to the experimental data, find $\\lambda$ and report its value below.\n",
    "#### Generate a graph for the glass transition temperature $T_g$ vs. degree of cure $\\alpha$ to compare experimental values with the analytical model.\n",
    "\n",
    "#### NOTE: $T_{g0}$ = -54.577, $T_{g\\infty}$ = 88.853,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The glass transition temperature is specifically relevant when trying to establish a range of temperatures over which a polymer is able to retain its mechanical properties. This range is commonly identified as \"Service temperature\" and in these conditions the polymer can perform its intended function without experiencing significant degradation or detrimental changes in its properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two composite parts (A and B) have been previously manufactured by infusion using Airstone 780E, cured isothermally at $80^\\circ$ C. It is known that the reached degree of cure at the end of the cycle for part A is $\\alpha$= 0.9, while part B was consolidated up to $\\alpha$= 0.95.\n",
    "#### Use the DiBenedetto equation and the parameters given in question 7 to obtain the glass transition temperatures $T_g$ for the two parts. How would the difference between the $T_g$ of the two parts affect their properties and potential use temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9 (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cure kinetics model applicable to the Airstone 780E mentioned in Question 8, is given below:\n",
    "#### $$\\frac{d\\alpha}{dt} = \\frac{A \\cdot exp(-\\frac{E}{RT})}{1+exp(C(\\alpha - \\alpha_{c} -\\alpha_{T}T)) }(1 - \\alpha)^n\\cdot \\alpha^m$$\n",
    "#### Where:\n",
    "#### A = 681085 1/s\n",
    "#### E = 59291 J/mol\n",
    "#### n = 1.67\n",
    "#### m = 0.12\n",
    "#### C = 47.7\n",
    "#### $\\alpha_{c}$= 0.77\n",
    "#### $\\alpha_{T}$ = 0.0016\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9.1: Using the cure kinetics model, calculate the cure time for an isothermal cure at $80^\\circ$ C to cure the part to 90% degree of cure (part A of Question 8). Compare this to the cure time needed to cure the part to 95% degree of cure at $80^\\circ$ C (part B from Question 8). Please give your view on the trade-off between cure time and attainable $T_g$ (see also question 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9.2: The production team needs to speed up production to a cure time of 60 minutes while reaching 95% degree of cure in the part. Which temperature would be needed to achieve this? Then, comment on the feasibility of using this cure temperature: which considerations and/or concerns would you share with the production team prior to implementation of this cure temperature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
